{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\news-headlines-dataset-for-sarcasm-detection\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# %pip install opendatasets\n",
    "# %pip install prophet\n",
    "\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import prophet\n",
    "\n",
    "od.download('https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28619, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['is_sarcastic']\n",
    "sentences = df['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        thirtysomething scientists unveil doomsday clo...\n",
       "1        dem rep. totally nails why congress is falling...\n",
       "2        eat your veggies: 9 deliciously different recipes\n",
       "3        inclement weather prevents liar from getting t...\n",
       "4        mother comes pretty close to using word 'strea...\n",
       "                               ...                        \n",
       "28614         jews to celebrate rosh hashasha or something\n",
       "28615    internal affairs investigator disappointed con...\n",
       "28616    the most beautiful acceptance speech this week...\n",
       "28617    mars probe destroyed by orbiting spielberg-gat...\n",
       "28618                   dad clarifies this not a food stop\n",
       "Name: headline, Length: 28619, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing import strip_tags, strip_numeric, strip_multiple_whitespaces, stem_text, strip_punctuation, remove_stopwords\n",
    "from gensim.parsing import  preprocess_string\n",
    "import re\n",
    "\n",
    "\n",
    "# Custom filter method\n",
    "transform_to_lower = lambda s: s.lower()\n",
    "\n",
    "remove_single_char = lambda s: re.sub(r'\\s+\\w{1}\\s+', '', s)\n",
    "\n",
    "# Filters to be executed in pipeline\n",
    "CLEAN_FILTERS = [strip_tags,\n",
    "                strip_numeric,\n",
    "                strip_punctuation, \n",
    "                strip_multiple_whitespaces, \n",
    "                transform_to_lower,\n",
    "                # remove_stopwords,\n",
    "                remove_single_char]\n",
    "\n",
    "# Method does the filtering of all the unrelevant text elements\n",
    "def cleaning_pipe(document):\n",
    "    # Invoking gensim.parsing.preprocess_string method with set of filters\n",
    "    processed_words = preprocess_string(document, CLEAN_FILTERS)\n",
    "    \n",
    "    return processed_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_processed = sentences.apply(cleaning_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirtysomething scientists unveil doomsday clock of hair loss\n",
      "['thirtysomething', 'scientists', 'unveil', 'doomsday', 'clock', 'of', 'hair', 'loss']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(sentences_processed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras import layers, models, Sequential\n",
    "\n",
    "vocab_size = 50000\n",
    "maxlen = 200\n",
    "\n",
    "tokenizer = Tokenizer( num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thirtysomething scientists unveil doomsday clock of hair loss\n",
      "[27, 13, 109, 638, 17, 781, 67, 4774, 5, 43, 1939]\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=maxlen, truncating='post')\n",
    "print(train_sentences[0])\n",
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=maxlen, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#  prefetch and cache data for faster training\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_padded, train_labels))\n",
    "train_dataset = train_dataset.batch(32, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_padded, test_labels))\n",
    "test_dataset = test_dataset.batch(32, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Embedding(vocab_size, 16, input_length=maxlen),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(24, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_padded, train_labels, epochs=30, validation_data=(test_padded, test_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, None, 64)          3200000   \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, None, 128)        66048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 64)               41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,311,489\n",
      "Trainable params: 3,311,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential([\n",
    "    layers.Embedding(vocab_size, 64),\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(32)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "716/716 [==============================] - 37s 45ms/step - loss: 0.3797 - accuracy: 0.8216 - val_loss: 0.3013 - val_accuracy: 0.8691\n",
      "Epoch 2/50\n",
      "716/716 [==============================] - 28s 40ms/step - loss: 0.1436 - accuracy: 0.9451 - val_loss: 0.3249 - val_accuracy: 0.8655\n",
      "Epoch 3/50\n",
      "716/716 [==============================] - 28s 39ms/step - loss: 0.0460 - accuracy: 0.9848 - val_loss: 0.5107 - val_accuracy: 0.8517\n",
      "Epoch 4/50\n",
      "716/716 [==============================] - 28s 40ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.5719 - val_accuracy: 0.8471\n",
      "Epoch 5/50\n",
      "716/716 [==============================] - 28s 39ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.7229 - val_accuracy: 0.8489\n",
      "Epoch 6/50\n",
      "716/716 [==============================] - 28s 40ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.7722 - val_accuracy: 0.8484\n",
      "Epoch 7/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.7573 - val_accuracy: 0.8450\n",
      "Epoch 8/50\n",
      "716/716 [==============================] - 28s 40ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.9014 - val_accuracy: 0.8393\n",
      "Epoch 9/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.9027 - val_accuracy: 0.8431\n",
      "Epoch 10/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.9229 - val_accuracy: 0.8375\n",
      "Epoch 11/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 1.0368 - val_accuracy: 0.8456\n",
      "Epoch 12/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.7729 - val_accuracy: 0.8410\n",
      "Epoch 13/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 1.0622 - val_accuracy: 0.8401\n",
      "Epoch 14/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.9333 - val_accuracy: 0.8417\n",
      "Epoch 15/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.9150 - val_accuracy: 0.8431\n",
      "Epoch 16/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 1.0835 - val_accuracy: 0.8440\n",
      "Epoch 17/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 9.9708e-04 - accuracy: 0.9997 - val_loss: 1.0207 - val_accuracy: 0.8428\n",
      "Epoch 18/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 4.4133e-05 - accuracy: 1.0000 - val_loss: 1.2432 - val_accuracy: 0.8421\n",
      "Epoch 19/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 3.4033e-06 - accuracy: 1.0000 - val_loss: 1.2852 - val_accuracy: 0.8419\n",
      "Epoch 20/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 2.1241e-06 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.8421\n",
      "Epoch 21/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 1.3795e-06 - accuracy: 1.0000 - val_loss: 1.3642 - val_accuracy: 0.8424\n",
      "Epoch 22/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 9.0861e-07 - accuracy: 1.0000 - val_loss: 1.4032 - val_accuracy: 0.8428\n",
      "Epoch 23/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 6.0457e-07 - accuracy: 1.0000 - val_loss: 1.4429 - val_accuracy: 0.8429\n",
      "Epoch 24/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 4.0310e-07 - accuracy: 1.0000 - val_loss: 1.4825 - val_accuracy: 0.8429\n",
      "Epoch 25/50\n",
      "716/716 [==============================] - 31s 44ms/step - loss: 2.7049e-07 - accuracy: 1.0000 - val_loss: 1.5217 - val_accuracy: 0.8426\n",
      "Epoch 26/50\n",
      "716/716 [==============================] - 31s 43ms/step - loss: 1.8231e-07 - accuracy: 1.0000 - val_loss: 1.5612 - val_accuracy: 0.8428\n",
      "Epoch 27/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 1.2291e-07 - accuracy: 1.0000 - val_loss: 1.6004 - val_accuracy: 0.8435\n",
      "Epoch 28/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 8.3258e-08 - accuracy: 1.0000 - val_loss: 1.6400 - val_accuracy: 0.8435\n",
      "Epoch 29/50\n",
      "716/716 [==============================] - 30s 42ms/step - loss: 5.6551e-08 - accuracy: 1.0000 - val_loss: 1.6787 - val_accuracy: 0.8428\n",
      "Epoch 30/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 3.8651e-08 - accuracy: 1.0000 - val_loss: 1.7183 - val_accuracy: 0.8431\n",
      "Epoch 31/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 2.6473e-08 - accuracy: 1.0000 - val_loss: 1.7566 - val_accuracy: 0.8433\n",
      "Epoch 32/50\n",
      "716/716 [==============================] - 30s 41ms/step - loss: 1.8339e-08 - accuracy: 1.0000 - val_loss: 1.7945 - val_accuracy: 0.8433\n",
      "Epoch 33/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 1.2794e-08 - accuracy: 1.0000 - val_loss: 1.8317 - val_accuracy: 0.8429\n",
      "Epoch 34/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 9.0417e-09 - accuracy: 1.0000 - val_loss: 1.8676 - val_accuracy: 0.8433\n",
      "Epoch 35/50\n",
      "716/716 [==============================] - 31s 43ms/step - loss: 6.4417e-09 - accuracy: 1.0000 - val_loss: 1.9020 - val_accuracy: 0.8433\n",
      "Epoch 36/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 4.6809e-09 - accuracy: 1.0000 - val_loss: 1.9360 - val_accuracy: 0.8433\n",
      "Epoch 37/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 3.4307e-09 - accuracy: 1.0000 - val_loss: 1.9688 - val_accuracy: 0.8435\n",
      "Epoch 38/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 2.5579e-09 - accuracy: 1.0000 - val_loss: 1.9992 - val_accuracy: 0.8433\n",
      "Epoch 39/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 1.9406e-09 - accuracy: 1.0000 - val_loss: 2.0289 - val_accuracy: 0.8436\n",
      "Epoch 40/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 1.4729e-09 - accuracy: 1.0000 - val_loss: 2.0580 - val_accuracy: 0.8442\n",
      "Epoch 41/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 1.1587e-09 - accuracy: 1.0000 - val_loss: 2.0845 - val_accuracy: 0.8440\n",
      "Epoch 42/50\n",
      "716/716 [==============================] - 38s 53ms/step - loss: 9.1938e-10 - accuracy: 1.0000 - val_loss: 2.1097 - val_accuracy: 0.8442\n",
      "Epoch 43/50\n",
      "716/716 [==============================] - 30s 42ms/step - loss: 7.4913e-10 - accuracy: 1.0000 - val_loss: 2.1341 - val_accuracy: 0.8443\n",
      "Epoch 44/50\n",
      "716/716 [==============================] - 29s 40ms/step - loss: 6.1265e-10 - accuracy: 1.0000 - val_loss: 2.1566 - val_accuracy: 0.8445\n",
      "Epoch 45/50\n",
      "716/716 [==============================] - 30s 42ms/step - loss: 5.1455e-10 - accuracy: 1.0000 - val_loss: 2.1766 - val_accuracy: 0.8445\n",
      "Epoch 46/50\n",
      "716/716 [==============================] - 30s 42ms/step - loss: 4.3872e-10 - accuracy: 1.0000 - val_loss: 2.1946 - val_accuracy: 0.8447\n",
      "Epoch 47/50\n",
      "716/716 [==============================] - 31s 43ms/step - loss: 3.8351e-10 - accuracy: 1.0000 - val_loss: 2.2112 - val_accuracy: 0.8447\n",
      "Epoch 48/50\n",
      "716/716 [==============================] - 30s 42ms/step - loss: 3.4715e-10 - accuracy: 1.0000 - val_loss: 2.2262 - val_accuracy: 0.8447\n",
      "Epoch 49/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 3.1721e-10 - accuracy: 1.0000 - val_loss: 2.2398 - val_accuracy: 0.8443\n",
      "Epoch 50/50\n",
      "716/716 [==============================] - 29s 41ms/step - loss: 2.8927e-10 - accuracy: 1.0000 - val_loss: 2.2531 - val_accuracy: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2417ec3f970>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(train_padded, train_labels, epochs=50, validation_data=(test_padded, test_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# print(\"\\nAccuracy-\",accuracy_score(y_test, y_pred_knn),'\\n')\n",
    "# cm = confusion_matrix(y_test, y_pred_knn)\n",
    "# sns.heatmap(cm, annot=True)\n",
    "# print(classification_report(y_test,y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67bfac4f4aefe1c16f1836a62d55b6e6baa7aba1ac5ce70e93ee8e90eb4f073a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
